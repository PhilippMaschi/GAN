{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, classes, channels, img_size, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.channels = channels\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
    "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Linear(in_features = self.latent_dim + self.classes, out_features = 64),\n",
    "            nn.LeakyReLU(),\n",
    "            # 2nd layer\n",
    "            nn.Linear(in_features = 64, out_features = 128),\n",
    "            nn.LeakyReLU(),\n",
    "            # 3rd layer\n",
    "            nn.BatchNorm1d(num_features = 128, momentum = 0.8),\n",
    "            # 4th layer\n",
    "            nn.Linear(in_features = 128, out_features = 64),\n",
    "            nn.LeakyReLU(),\n",
    "            # 5th layer\n",
    "            nn.Linear(in_features = 64, out_features = int(np.prod(self.img_shape)))\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        z = torch.cat((self.label_embedding(labels), noise), -1)\n",
    "        x = self.model(z)\n",
    "        x = x.view(x.size(0), *self.img_shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, classes, channels, img_size, latent_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.channels = channels\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
    "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
    "        self.adv_loss = torch.nn.BCELoss()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Linear(in_features = self.classes + int(np.prod(self.img_shape)), out_features = 64),\n",
    "            nn.LeakyReLU(),\n",
    "            # 2nd layer\n",
    "            nn.Linear(in_features = 64, out_features = 128),\n",
    "            nn.LeakyReLU(),\n",
    "            # 3rd layer\n",
    "            nn.Linear(in_features = 128, out_features = 128),\n",
    "            nn.LeakyReLU(),\n",
    "            # 4th layer\n",
    "            nn.Linear(in_features = 128, out_features = 64),\n",
    "            nn.LeakyReLU(),\n",
    "            # 5th layer\n",
    "            nn.Dropout(p = 0.4),\n",
    "            # 6th layer\n",
    "            nn.Linear(in_features = 64, out_features = 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, image, labels):\n",
    "        x = torch.cat((image.view(image.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        display(x.shape)\n",
    "        return self.model(x)\n",
    "\n",
    "    def loss(self, output, label):\n",
    "        return self.adv_loss(output, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "\n",
    "def to_np(var):\n",
    "    \"\"\"Exports torch.Tensor to Numpy array.\n",
    "    \"\"\"\n",
    "    return var.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def create_folder(folder_path):\n",
    "    \"\"\"Create a folder if it does not exist.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "    except OSError as _e:\n",
    "        if _e.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "\n",
    "def clear_folder(folder_path):\n",
    "    \"\"\"Clear all contents recursively if the folder exists.\n",
    "    Create the folder if it has been accidently deleted.\n",
    "    \"\"\"\n",
    "    create_folder(folder_path)\n",
    "    for the_file in os.listdir(folder_path):\n",
    "        _file_path = os.path.join(folder_path, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(_file_path):\n",
    "                os.unlink(_file_path)\n",
    "            elif os.path.isdir(_file_path):\n",
    "                shutil.rmtree(_file_path)\n",
    "        except OSError as _e:\n",
    "            print(_e)\n",
    "\n",
    "\n",
    "class StdOut(object):\n",
    "    \"\"\"Redirect stdout to file, and print to console as well.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_file):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(output_file, \"a\")\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.terminal.flush()\n",
    "        self.log.write(message)\n",
    "        self.log.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "\n",
    "def boolean_string(s):\n",
    "    if s not in {'False', 'True'}:\n",
    "        raise ValueError('Not a valid boolean string')\n",
    "    return s == 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self,\n",
    "                 name,\n",
    "                 device,\n",
    "                 data_loader,\n",
    "                 classes,\n",
    "                 channels,\n",
    "                 img_size,\n",
    "                 latent_dim,\n",
    "                 style_dim=2):\n",
    "        self.name = name\n",
    "        self.device = device\n",
    "        self.data_loader = data_loader\n",
    "        self.classes = classes\n",
    "        self.channels = channels\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.style_dim = style_dim\n",
    "        self.netG = Generator(self.classes, self.channels, self.img_size, self.latent_dim)\n",
    "        self.netG.to(self.device)\n",
    "        self.netD = Discriminator(self.classes, self.channels, self.img_size, self.latent_dim)\n",
    "        self.netD.to(self.device)\n",
    "        self.optim_G = None\n",
    "        self.optim_D = None\n",
    "        self.optim_info = None\n",
    "\n",
    "    @property\n",
    "    def generator(self):\n",
    "        return self.netG\n",
    "\n",
    "    @property\n",
    "    def discriminator(self):\n",
    "        return self.netD\n",
    "\n",
    "    def create_optim(self, lr, alpha=0.5, beta=0.999):\n",
    "        self.optim_G = torch.optim.Adam(filter(lambda p: p.requires_grad,\n",
    "                                        self.netG.parameters()),\n",
    "                                        lr=lr,\n",
    "                                        betas=(alpha, beta))\n",
    "        self.optim_D = torch.optim.Adam(filter(lambda p: p.requires_grad,\n",
    "                                        self.netD.parameters()),\n",
    "                                        lr=lr,\n",
    "                                        betas=(alpha, beta))\n",
    "\n",
    "    def _to_onehot(self, var, dim):\n",
    "        res = torch.zeros((var.shape[0], dim), device=self.device)\n",
    "        res[range(var.shape[0]), var] = 1.\n",
    "        return res\n",
    "\n",
    "    def train(self,\n",
    "              epochs,\n",
    "              log_interval=100,\n",
    "              out_dir='',\n",
    "              verbose=True):\n",
    "        self.netG.train()\n",
    "        self.netD.train()\n",
    "        viz_z = torch.zeros((self.data_loader.batch_size, self.latent_dim), device=self.device)\n",
    "        viz_noise = torch.randn(self.data_loader.batch_size, self.latent_dim, device=self.device)\n",
    "        nrows = self.data_loader.batch_size // 8\n",
    "        viz_label = torch.LongTensor(np.array([num for _ in range(nrows) for num in range(8)])).to(self.device)\n",
    "        viz_onehot = self._to_onehot(viz_label, dim=self.classes)\n",
    "        viz_style = torch.zeros((self.data_loader.batch_size, self.style_dim), device=self.device)\n",
    "        total_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            batch_time = time.time()\n",
    "            for batch_idx, (data, target) in enumerate(self.data_loader):\n",
    "\n",
    "                # Old code\n",
    "                #data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                # New code\n",
    "                #\"\"\"\n",
    "                data = torch.stack(data)\n",
    "                data = torch.tensor(data, dtype = torch.float32)\n",
    "                target = torch.tensor(target)\n",
    "                data, target = data.T.to(self.device), target.to(self.device)\n",
    "                #\"\"\"\n",
    "\n",
    "                batch_size = data.size(0)\n",
    "                real_label = torch.full((batch_size, 1), 1., device=self.device)\n",
    "                fake_label = torch.full((batch_size, 1), 0., device=self.device)\n",
    "\n",
    "                # Train G\n",
    "                self.netG.zero_grad()\n",
    "                z_noise = torch.randn(batch_size, self.latent_dim, device=self.device)\n",
    "                x_fake_labels = torch.randint(0, self.classes, (batch_size,), device=self.device)\n",
    "                x_fake = self.netG(z_noise, x_fake_labels)\n",
    "                display('x_fake', x_fake.shape, 'x_fake_labels', x_fake_labels.shape)\n",
    "                y_fake_g = self.netD(x_fake, x_fake_labels)\n",
    "                g_loss = self.netD.loss(y_fake_g, real_label)\n",
    "                g_loss.backward()\n",
    "                self.optim_G.step()\n",
    "\n",
    "                # Train D\n",
    "                self.netD.zero_grad()\n",
    "                display('data', data.shape, 'target', target.shape)\n",
    "                y_real = self.netD(data, target)\n",
    "                d_real_loss = self.netD.loss(y_real, real_label)\n",
    "\n",
    "                y_fake_d = self.netD(x_fake.detach(), x_fake_labels)\n",
    "                d_fake_loss = self.netD.loss(y_fake_d, fake_label)\n",
    "                d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                self.optim_D.step()\n",
    "\n",
    "                if verbose and batch_idx % log_interval == 0 and batch_idx > 0:\n",
    "                    print('Epoch {} [{}/{}] loss_D: {:.4f} loss_G: {:.4f} time: {:.2f}'.format(\n",
    "                            epoch, batch_idx, len(self.data_loader),\n",
    "                            d_loss.mean().item(),\n",
    "                            g_loss.mean().item(),\n",
    "                            time.time() - batch_time))\n",
    "                    vutils.save_image(data, os.path.join(out_dir, 'real_samples.png'), normalize=True)\n",
    "                    with torch.no_grad():\n",
    "                        viz_sample = self.netG(viz_noise, viz_label)\n",
    "                        vutils.save_image(viz_sample, os.path.join(out_dir, 'fake_samples_{}.png'.format(epoch)), nrow=8, normalize=True)\n",
    "                    batch_time = time.time()\n",
    "\n",
    "            self.save_to(path=out_dir, name=self.name, verbose=False)\n",
    "        if verbose:\n",
    "            print('Total train time: {:.2f}'.format(time.time() - total_time))\n",
    "\n",
    "    def save_to(self,\n",
    "                path='',\n",
    "                name=None,\n",
    "                verbose=True):\n",
    "        if name is None:\n",
    "            name = self.name\n",
    "        if verbose:\n",
    "            print('\\nSaving models to {}_G.pt and {}_D.pt ...'.format(name, name))\n",
    "        torch.save(self.netG.state_dict(), os.path.join(path, '{}_G.pt'.format(name)))\n",
    "        torch.save(self.netD.state_dict(), os.path.join(path, '{}_D.pt'.format(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pandas as pd\n",
    "from preprocessing import remove_incomplete_days\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "\n",
    "def main(batch_size, model, classes, channels, img_size, latent_dim, lr, epochs, log_interval, out_dir):\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "    # Original dataset\n",
    "    dataset = dset.MNIST(root = '~/Data/mnist', download = True, transform = transforms.Compose([transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]))\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "    return dataset, dataloader\n",
    "\n",
    "    # New dataset (Enercoop)\n",
    "    \"\"\"\n",
    "    df_loadProfiles = pd.read_parquet(r'data/load_profiles.parquet.gzip')\n",
    "    df_loadProfiles = remove_incomplete_days(df_loadProfiles)\n",
    "    df_temp = df_loadProfiles.pivot_table(values = '1163', index = ['date', 'month of the year', 'day off'], columns = 'hour of the day').reset_index()\n",
    "    labels = list((df_temp['month of the year'].astype(str) + df_temp['day off'].astype(str)).astype(int))\n",
    "    df_temp.drop(['date', 'month of the year', 'day off'], axis = 1, inplace = True)\n",
    "    df_temp = pd.DataFrame(minmax_scale(df_temp, feature_range = (-0.5, 0.5), axis = 1))\n",
    "    timeSeries = df_temp.values.tolist()\n",
    "    dataloader = torch.utils.data.DataLoader([[timeSeries[i], labels[i]] for i in range(len(labels))], shuffle = True, batch_size = batch_size)\n",
    "    \"\"\"\n",
    "\n",
    "    model = Model(model, device, dataloader, classes, channels, img_size, latent_dim)\n",
    "    model.create_optim(lr)\n",
    "\n",
    "    # Train\n",
    "    model.train(epochs, log_interval, out_dir, True)\n",
    "\n",
    "    model.save_to('')\n",
    "\n",
    "#main(batch_size = 128, model = 'cgan', classes = 10, channels = 1, img_size = 64, latent_dim = 100, lr = 0.002, epochs = 2, log_interval = 100, out_dir = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main(batch_size = 100, model = 'cgan', classes = 24, channels = 1, img_size = 24, latent_dim = 20, lr = 0.0004, epochs = 2, log_interval = 100, out_dir = 'output')\n",
    "dataset, dataloader = main(batch_size = 128, model = 'cgan', classes = 10, channels = 1, img_size = 64, latent_dim = 100, lr = 0.002, epochs = 2, log_interval = 100, out_dir = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocessing import remove_incomplete_days\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import torch\n",
    "\n",
    "df_loadProfiles = pd.read_parquet(r'data/load_profiles.parquet.gzip')\n",
    "df_loadProfiles = remove_incomplete_days(df_loadProfiles)\n",
    "df_temp = df_loadProfiles.pivot_table(values = '1163', index = ['date', 'month of the year', 'day off'], columns = 'hour of the day').reset_index()\n",
    "labels = list((df_temp['month of the year'].astype(str) + df_temp['day off'].astype(str)).astype(int))\n",
    "df_temp.drop(['date', 'month of the year', 'day off'], axis = 1, inplace = True)\n",
    "df_temp = pd.DataFrame(minmax_scale(df_temp, feature_range = (-0.5, 0.5), axis = 1))\n",
    "timeSeries = df_temp.values.tolist()\n",
    "trainloader = torch.utils.data.DataLoader([[timeSeries[i], labels[i]] for i in range(len(labels))], shuffle = True, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DoppelGANger')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79b4750ed2717c744363ddeeb308685b8aa38c66aec97c408e6db81441baebf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

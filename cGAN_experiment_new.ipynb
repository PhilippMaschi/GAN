{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import uniform\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoid(x, x0, A, B):\n",
    "    y = A*np.sin(x0 + B*x)\n",
    "    return y\n",
    "\n",
    "def get_sample(x_dim):\n",
    "    x0 = uniform(low = 0, high = 1)\n",
    "    #A = uniform(low = 0.5, high = 0.8)\n",
    "    A = 1\n",
    "    B = uniform(low = 1.2, high = 1.5)\n",
    "    sample = np.array([sinusoid(item, x0, A, B) for item in np.linspace(0, 6*np.pi, x_dim)])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 64\n",
    "sample_size = 25\n",
    "samples = np.stack([get_sample(x_dim) for idx in range(sample_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "plt.plot(samples[sample_idx]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim, full, randn, no_grad\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, dimLatent):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dimLatent = dimLatent\n",
    "        self.model = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Linear(in_features = self.dimLatent, out_features = 64),\n",
    "            #nn.ReLU(),\n",
    "            nn.LeakyReLU(),\n",
    "            # 2nd layer\n",
    "            nn.Linear(in_features = 64, out_features = 128),\n",
    "            #nn.ReLU(),\n",
    "            nn.LeakyReLU(),\n",
    "            # 3rd layer\n",
    "            nn.Linear(in_features = 128, out_features = 64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        x = self.model(noise)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, featureCount):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.featureCount = featureCount\n",
    "        self.model = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Linear(in_features = self.featureCount, out_features = 128),\n",
    "            nn.LeakyReLU(),\n",
    "            # 2nd layer\n",
    "            nn.Linear(in_features = 128, out_features = 64),\n",
    "            nn.LeakyReLU(),\n",
    "            # 3rd layer\n",
    "            nn.Linear(in_features = 64, out_features = 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        bool_ = self.model(data)\n",
    "        return bool_\n",
    "\n",
    "\n",
    "class GAN(object):\n",
    "    def __init__(self, device, dataLoader, dimLatent, featureCount, lr, epochCount):\n",
    "        self.device = device\n",
    "        self.dataLoader = dataLoader\n",
    "        self.dimLatent = dimLatent\n",
    "        self.featureCount = featureCount\n",
    "        self.lr = lr\n",
    "        self.epochCount = epochCount\n",
    "\n",
    "        # Initialize generator\n",
    "        self.Gen = Generator(dimLatent)\n",
    "        self.Gen.to(self.device)\n",
    "\n",
    "        # Initialize discriminator\n",
    "        self.Dis = Discriminator(featureCount)\n",
    "        self.Dis.to(self.device)\n",
    "    \n",
    "        # Initialize optimizers\n",
    "        self.optimGen = optim.Adam(params = self.Gen.parameters(), lr = self.lr)\n",
    "        self.optimDis = optim.Adam(params = self.Dis.parameters(), lr = self.lr)\n",
    "\n",
    "        # Initialize the loss function\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "        self.df_loss = pd.DataFrame(columns = ['epoch', 'batch index', 'discriminator loss (real data)', 'discriminator loss (fake data)', 'discriminator loss', 'generator loss'])\n",
    "        self.iterCount = 0\n",
    "        self.noiseFixed = randn(featureCount, dimLatent, device = device)\n",
    "    \n",
    "    def train(self):\n",
    "        for epoch in tqdm(range(self.epochCount)):\n",
    "            for batchIdx, data in enumerate(self.dataLoader):\n",
    "                data = data.to(device = self.device, dtype = torch.float32)\n",
    "\n",
    "                # Train discriminator with real data\n",
    "                self.Dis.zero_grad()                                                                                    #set the gradients to zero for every mini-batch\n",
    "                yReal = self.Dis(data)                                                                                  #train discriminator with real data\n",
    "                labelReal = full(size = (data.size(0), 1), fill_value = 1, device = self.device, dtype = torch.float32) #a tensor containing only ones\n",
    "                lossDisReal = self.criterion(yReal, labelReal)                                                          #calculate the loss\n",
    "                lossDisReal.backward()                                                                                  #calculate new gradients\n",
    "\n",
    "                # Train discriminator with fake data\n",
    "                noise = randn(data.size(0), self.dimLatent, device = self.device)                                       #create a tensor filled with random numbers\n",
    "                labelFake = full(size = (data.size(0), 1), fill_value = 0, device = self.device, dtype = torch.float32) #a tensor containing only zeros\n",
    "                xFake = self.Gen(noise)                                                                                 #create fake data from noise with generator\n",
    "                yFake = self.Dis(xFake.detach())                                                                        #let the discriminator label the fake data (`.detach()` creates a copy of the tensor)\n",
    "                lossDisFake = self.criterion(yFake, labelFake)\n",
    "                lossDisFake.backward()\n",
    "\n",
    "                lossDis = (lossDisReal + lossDisFake)                                                                   #compute the total discriminator loss\n",
    "                self.optimDis.step()                                                                                    #update the discriminator\n",
    "\n",
    "                # Train generator (now that we fed the discriminator with fake data)\n",
    "                self.Gen.zero_grad()\n",
    "                yFake_2 = self.Dis(xFake)                                                                               #let the discriminator label the fake data (now that the discriminator is updated)\n",
    "                lossGen = self.criterion(yFake_2, labelReal)                                                            #calculate the generator loss (small if the discriminator thinks that `yFake_2 == labelReal`)\n",
    "                lossGen.backward()\n",
    "                self.optimGen.step()\n",
    "\n",
    "                # Log the progress\n",
    "                self.df_loss.loc[len(self.df_loss)] = [epoch, batchIdx, lossDisReal.detach().cpu().numpy(), lossDisFake.detach().cpu().numpy(), lossDis.detach().cpu().numpy(), lossGen.detach().cpu().numpy()]\n",
    "                if self.iterCount % 500 == 0:\n",
    "                    with no_grad():\n",
    "                        xFakeTest = self.Gen(self.noiseFixed)\n",
    "                        plt.plot(xFakeTest.detach().cpu().numpy()[1])\n",
    "                        plt.show();\n",
    "                        yFakeTest = self.Dis(xFakeTest)\n",
    "                        print(yFakeTest.detach().cpu().numpy().reshape(-1))\n",
    "                self.iterCount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')\n",
    "dataLoader = DataLoader(samples)\n",
    "dimLatent = 8\n",
    "featureCount = samples.shape[1]\n",
    "lr = 1e-4\n",
    "epochCount = 250\n",
    "\n",
    "model = GAN(device, dataLoader, dimLatent, featureCount, lr, epochCount)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.df_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.df_loss['generator loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.df_loss['discriminator loss (real data)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.df_loss['discriminator loss (fake data)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.df_loss['discriminator loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DoppelGANger')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79b4750ed2717c744363ddeeb308685b8aa38c66aec97c408e6db81441baebf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
